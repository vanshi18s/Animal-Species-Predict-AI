{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2197760,"sourceType":"datasetVersion","datasetId":1316317},{"sourceId":9727095,"sourceType":"datasetVersion","datasetId":5952108}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimg_height, img_width = 150, 150\nbatch_size = 32\n\ntrain_data = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.2)\n\ntrain_generator = train_data.flow_from_directory('/kaggle/input/animals-detection-images-dataset/train', \ntarget_size = (img_height, img_width),batch_size=batch_size,class_mode='categorical',subset='training')\n\nvalidation_generator = train_data.flow_from_directory('/kaggle/input/animals-detection-images-dataset/test',\ntarget_size = (img_height, img_width),batch_size=batch_size,class_mode='categorical',subset='validation')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-26T09:15:29.513473Z","iopub.execute_input":"2024-10-26T09:15:29.514636Z","iopub.status.idle":"2024-10-26T09:15:36.521855Z","shell.execute_reply.started":"2024-10-26T09:15:29.514564Z","shell.execute_reply":"2024-10-26T09:15:36.520156Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Found 18083 images belonging to 80 classes.\nFound 1267 images belonging to 80 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras import layers, models\n\nmodel =models.Sequential([layers.Conv2D(32,(3,3), activation='relu',\ninput_shape=(img_height, img_width,3)),layers.MaxPooling2D(pool_size=(2,2)),\nlayers.Conv2D(64,(3,3), activation='relu'),layers.MaxPooling2D(pool_size=(2,2)) ,\nlayers.Conv2D(128,(3,3), activation='relu'),layers.MaxPooling2D(pool_size=(2,2)),\nlayers.Flatten(),layers.Dense(128, activation='relu'),\nlayers.Dense(len(train_generator.class_indices),activation='softmax')])\n              \nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])              ","metadata":{"execution":{"iopub.status.busy":"2024-10-26T09:15:49.330907Z","iopub.execute_input":"2024-10-26T09:15:49.331376Z","iopub.status.idle":"2024-10-26T09:15:49.441177Z","shell.execute_reply.started":"2024-10-26T09:15:49.331333Z","shell.execute_reply":"2024-10-26T09:15:49.439967Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator, steps_per_epoch=train_generator.samples//batch_size,\nvalidation_data=validation_generator, validation_steps=validation_generator.samples//batch_size,\nepochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-10-26T09:17:04.988486Z","iopub.execute_input":"2024-10-26T09:17:04.988950Z","iopub.status.idle":"2024-10-26T10:07:34.012679Z","shell.execute_reply.started":"2024-10-26T09:17:04.988909Z","shell.execute_reply":"2024-10-26T10:07:34.007591Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 1s/step - accuracy: 0.1017 - loss: 3.9157 - val_accuracy: 0.0994 - val_loss: 3.9771\nEpoch 2/10\n\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359us/step - accuracy: 0.1562 - loss: 3.4811 - val_accuracy: 0.0526 - val_loss: 4.0969\nEpoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 1s/step - accuracy: 0.1811 - loss: 3.4553 - val_accuracy: 0.1338 - val_loss: 3.7573\nEpoch 4/10\n\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313us/step - accuracy: 0.1562 - loss: 3.1913 - val_accuracy: 0.2632 - val_loss: 3.2804\nEpoch 5/10\n\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 1s/step - accuracy: 0.2341 - loss: 3.1240 - val_accuracy: 0.1506 - val_loss: 3.7079\nEpoch 6/10\n\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 22ms/step - accuracy: 0.3125 - loss: 3.1069 - val_accuracy: 0.0526 - val_loss: 3.8616\nEpoch 7/10\n\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 989ms/step - accuracy: 0.3166 - loss: 2.6954 - val_accuracy: 0.1691 - val_loss: 3.6000\nEpoch 8/10\n\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242us/step - accuracy: 0.1875 - loss: 3.2508 - val_accuracy: 0.1053 - val_loss: 3.3773\nEpoch 9/10\n\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 997ms/step - accuracy: 0.4424 - loss: 2.0988 - val_accuracy: 0.1474 - val_loss: 4.0788\nEpoch 10/10\n\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.5312 - loss: 1.8485 - val_accuracy: 0.2105 - val_loss: 3.2380\n","output_type":"stream"}]},{"cell_type":"code","source":"loss, accuracy = model.evaluate(validation_generator)\nprint(f'Validation Accuracy : {accuracy:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-10-26T10:44:31.210913Z","iopub.execute_input":"2024-10-26T10:44:31.211661Z","iopub.status.idle":"2024-10-26T10:44:53.860300Z","shell.execute_reply.started":"2024-10-26T10:44:31.211578Z","shell.execute_reply":"2024-10-26T10:44:53.858979Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 537ms/step - accuracy: 0.1419 - loss: 4.1088\nValidation Accuracy : 0.15\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing import image\ndef predict_species(img_path):\n    img=image.load_img(img_path,target_size=(img_height,img_width))\n    img_array=image.img_to_array(img)\n    img_array=np.expand_dims(img_array,axis=0)/255.0\n    predictions=model.predict(img_array)\n    class_index=np.argmax(predictions)\n    return list(train_generator.class_indices.keys())[class_index]\n\nspecies=predict_species('/kaggle/input/elephant-photo/pexels-hsapir-1054655.jpg')\nprint(f'This image is predicted to be: {species}')","metadata":{"execution":{"iopub.status.busy":"2024-10-26T11:04:31.758326Z","iopub.execute_input":"2024-10-26T11:04:31.759110Z","iopub.status.idle":"2024-10-26T11:04:32.531510Z","shell.execute_reply.started":"2024-10-26T11:04:31.759051Z","shell.execute_reply":"2024-10-26T11:04:32.530135Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\nThis image is predicted to be: Elephant\n","output_type":"stream"}]}]}